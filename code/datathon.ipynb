{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>DG3</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  is_female  DG3     ...      \\\n",
       "0    3   32  3.0  NaN  323011  3854   481  1975          1    3     ...       \n",
       "1    2   26  NaN  8.0  268131  2441   344  1981          1    8     ...       \n",
       "2    1   16  NaN  7.0  167581   754   143  1995          1    3     ...       \n",
       "3    4   44  5.0  NaN  445071  5705   604  1980          1    3     ...       \n",
       "4    4   43  NaN  6.0  436161  5645   592  1958          1    3     ...       \n",
       "\n",
       "    GN1 GN1_OTHERS  GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  GN4_OTHERS  GN5  \\\n",
       "0  99.0        NaN   99         NaN   99         NaN   99         NaN   99   \n",
       "1   NaN        NaN    1         NaN    2         NaN    2         NaN    2   \n",
       "2   1.0        NaN    2         NaN    2         NaN    2         NaN    2   \n",
       "3   NaN        NaN    2         NaN    2         NaN   99         NaN   99   \n",
       "4   NaN        NaN    1         NaN    1         NaN    1         NaN    1   \n",
       "\n",
       "   GN5_OTHERS  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 1234 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\", low_memory=False)\n",
    "train.drop([\"train_id\"], axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18255, 1234)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data dimensions\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>417211</td>\n",
       "      <td>4479</td>\n",
       "      <td>535</td>\n",
       "      <td>1979</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322011</td>\n",
       "      <td>3803</td>\n",
       "      <td>476</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365011</td>\n",
       "      <td>5610</td>\n",
       "      <td>585</td>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>247061</td>\n",
       "      <td>2550</td>\n",
       "      <td>350</td>\n",
       "      <td>1991</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>358071</td>\n",
       "      <td>3233</td>\n",
       "      <td>400</td>\n",
       "      <td>1985</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1233 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  DG3  DG3A     ...      GN1  \\\n",
       "0    4   41  NaN  7.0  417211  4479   535  1979    8     1     ...      2.0   \n",
       "1    3   32  2.0  NaN  322011  3803   476  1993    1     4     ...      1.0   \n",
       "2    3   36  5.0  NaN  365011  5610   585  1980    3    99     ...      2.0   \n",
       "3    2   24  NaN  7.0  247061  2550   350  1991    3     2     ...      2.0   \n",
       "4    3   35  NaN  8.0  358071  3233   400  1985    3     4     ...      1.0   \n",
       "\n",
       "   GN1_OTHERS GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  GN4_OTHERS  GN5  \\\n",
       "0         NaN   1         NaN    3         NaN    3         NaN    3   \n",
       "1         NaN   1         NaN    1         NaN    1         NaN    1   \n",
       "2         NaN   2         NaN    2         NaN    2         NaN    2   \n",
       "3         NaN   2         NaN    2         NaN    2         NaN    2   \n",
       "4         NaN   1         NaN    1         NaN    1         NaN    1   \n",
       "\n",
       "   GN5_OTHERS  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 1233 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"../data/test.csv\", low_memory=False)\n",
    "test.drop([\"test_id\"], axis=1, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27285, 1233)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1113"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables listed in the data dictionary\n",
    "var = list(pd.read_excel(\"../data/data-dictionary.xlsx\", \n",
    "                         sheet_name=\"Codebook\")[\"Column Name\"]) + \\\n",
    "      list(pd.read_excel(\"../data/data-dictionary.xlsx\", \n",
    "                         sheet_name=\"AA Locations\", \n",
    "                         header=None)[0].dropna())\n",
    "len(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Discrepancy Between Data and its Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of variables present in train, but NOT present in dictionary (A-B)\n",
    "len(set(train.columns) - set(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables present in test, but NOT present in train (A-B)\n",
    "set(test.columns) - set(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_female'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables present in train, but NOT present in test\n",
    "set(train.columns) - set(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of variables present in dictionary, but NOT present in train\n",
    "len(set(var) - set(train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Discover NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'DG4_OTHERS', u'G2P2_2_OTHERS', u'G2P2_10_OTHERS', u'G2P2_12_OTHERS',\n",
       "       u'G2P2_15_OTHERS', u'MT12_99', u'MT13_4_OTHERS', u'MT13_96_OTHERS',\n",
       "       u'MT14_3_OTHERS', u'MT14_5_OTHERS', u'MT14_7_OTHERS', u'MM3_15',\n",
       "       u'MM3_16', u'MM4_16', u'MM5_4', u'MM5_5', u'MM5_15', u'MM5_16',\n",
       "       u'MM5A_4', u'MM5A_5', u'MM5A_15', u'MM5A_16', u'MM6_16', u'MM7_4',\n",
       "       u'MM7_5', u'MM7_15', u'MM7_16', u'MM8_15', u'MM8_16', u'MM11_4',\n",
       "       u'MM11_5', u'MM11_5_OTHERS', u'MM11_11_OTHERS', u'MM11_15', u'MM11_16',\n",
       "       u'MM15_OTHERS', u'MM17_13', u'MM17_15', u'MM17_17', u'MM17_19',\n",
       "       u'MM17_22', u'MM17_96', u'MM17A', u'MM38_OTHERS', u'MM40_14',\n",
       "       u'MM40_96', u'MMP4_7', u'MMP4_8', u'MMP4_96', u'FB28_3_OTHERS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty columns with no data\n",
    "emptyCol = train.columns[train.isnull().sum()==len(train)]\n",
    "emptyCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18255, 1184)\n",
      "(27285, 1183)\n"
     ]
    }
   ],
   "source": [
    "# Remove empty columns from train and test data\n",
    "train.drop(emptyCol, axis=1, inplace=True)\n",
    "test.drop(emptyCol, axis=1, inplace=True)\n",
    "print train.shape\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'AA5', u'DG3A_OTHERS', u'DG9b', u'DG9c', u'DG10b', u'DG10c', u'DG11b',\n",
       "       u'DG11c', u'DG12B_1', u'DG12B_2',\n",
       "       ...\n",
       "       u'FB28_1_OTHERS', u'FB28_2_OTHERS', u'FB28_4_OTHERS', u'FB28_96_OTHERS',\n",
       "       u'FB29_OTHERS', u'GN1_OTHERS', u'GN2_OTHERS', u'GN3_OTHERS',\n",
       "       u'GN4_OTHERS', u'GN5_OTHERS'],\n",
       "      dtype='object', length=823)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns where atleast 50% of the data are missing\n",
    "sparseCol = train.columns[train.isnull().sum()>=len(train)/2.]\n",
    "sparseCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12602, 18205, 10018, 11451, 11678, 12862, 12002, 13158, 14691,\n",
       "       18246, 17508, 18222, 17974,  9257, 18153, 18021, 17947, 10985,\n",
       "       15815, 18238, 18144, 14264, 14628, 18249, 15645, 18182, 17704,\n",
       "       18232, 18241, 18179, 18235, 18208, 17524, 17965, 17860, 18212,\n",
       "       18011, 18200, 18001, 18251, 18227, 18254, 18253, 18250,  9333,\n",
       "       18244, 18230, 15095, 18240, 12082, 18234, 11243, 18233, 17672,\n",
       "       15596, 17805, 18046, 18218, 18245, 16572, 18247, 18003, 16681,\n",
       "       18055, 18252, 17572, 11285, 14806, 18199, 18135, 11496, 18248,\n",
       "       17876, 18229, 11310,  9987, 18048, 18101, 18155, 18215, 18112,\n",
       "       18133, 18049, 18217, 18124, 18116, 18170, 18242, 18209, 18183,\n",
       "       17788, 17890, 17352, 18169, 18187, 18054, 18198, 18143, 18211,\n",
       "       18194, 18125, 18180, 17752, 18157, 18239, 18223, 18220, 18216,\n",
       "       18236, 18128, 18181, 17182, 18243, 17183, 18204, 18190, 18172,\n",
       "       18191, 18219, 18201, 18224, 18226, 18207, 18210, 18214, 18031,\n",
       "       18225, 18062, 17959, 18015, 17759, 17811, 17381, 17467, 17186,\n",
       "       18213, 17616, 14574, 16325, 16366, 16358, 15388, 16897, 18114,\n",
       "       18126, 13831, 18195, 13723, 18237, 16761, 17997, 18163, 17674,\n",
       "       16691, 15474, 18158, 18192, 17059, 12714, 18160, 18024, 17975,\n",
       "       17792, 17686, 17064,  9917, 18228, 17910, 16813, 17893, 18085,\n",
       "       18189, 18196, 18177])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN counts for columns with atleast 50% missing data\n",
    "train[sparseCol].isnull().sum().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18255, 361)\n",
      "(27285, 360)\n"
     ]
    }
   ],
   "source": [
    "# Remove columns with atleast 50% missing data from train and test data\n",
    "train.drop(sparseCol, axis=1, inplace=True)\n",
    "test.drop(sparseCol, axis=1, inplace=True)\n",
    "print train.shape\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DL14', 'DL4_96', 'DL4_99', 'LN2_RIndLngBEOth', 'LN2_WIndLngBEOth'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables present in train, but NOT present in data dictionary (A-B)\n",
    "set(train.columns) - set(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the data dictionary:  \n",
    "DL4_96 = DL4_24,  \n",
    "DL4_99 = DL4_25,   \n",
    "LN2_RIndLngBEOth = LN2_3 Reading specification,   \n",
    "LN2_WIndLngBEOth = LN2_4 Writing specification,  \n",
    "DL14 description is unknown\n",
    "\n",
    "Let's rename columns DL4_96 and DL4_99 in train and test data to match with the dictionary labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in train and test data to match with dictionary labels\n",
    "train.rename(columns={\"DL4_96\": \"DL4_24\", \"DL4_99\": \"DL4_25\"}, inplace=True)\n",
    "test.rename(columns={\"DL4_96\": \"DL4_24\", \"DL4_99\": \"DL4_25\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'AA6', u'DG9a', u'DL5', u'MT1A', u'MT7', u'MT15', u'MT17_1', u'MT17_2',\n",
       "       u'MT17_3', u'MT17_4',\n",
       "       ...\n",
       "       u'FB19B_2', u'FB19B_3', u'FB19B_4', u'FB19B_5', u'FB19B_96', u'FB20',\n",
       "       u'FB24', u'LN2_RIndLngBEOth', u'LN2_WIndLngBEOth', u'GN1'],\n",
       "      dtype='object', length=123)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 123 columns have NaN in train data\n",
    "missColTr = train.columns[train.isnull().sum()>0]\n",
    "missColTr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5653,  232, 6806,  757, 8922, 7012, 6173, 6759, 6380, 7839, 8670,\n",
       "         86,  425,   37,   11,    6,   47,   21,   10,    7,   34,   20,\n",
       "        159,   16, 2129, 5293, 7319, 7397, 4049, 6580,  769,  444,  297,\n",
       "        247,  263,   63, 1494, 5541, 6914, 6911, 4025])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts of NaN in train data\n",
    "train[missColTr].isnull().sum().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'AA6', u'DG9a', u'DL5', u'MT1A', u'MT7', u'MT15', u'MT17_1', u'MT17_2',\n",
       "       u'MT17_3', u'MT17_4',\n",
       "       ...\n",
       "       u'FB19B_2', u'FB19B_3', u'FB19B_4', u'FB19B_5', u'FB19B_96', u'FB20',\n",
       "       u'FB24', u'LN2_RIndLngBEOth', u'LN2_WIndLngBEOth', u'GN1'],\n",
       "      dtype='object', length=123)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 123 columns have NaN in test data\n",
    "missColTe = test.columns[test.isnull().sum()>0]\n",
    "missColTe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8459,   386, 10207,  1158, 13479, 10590,  8976, 10134,  9622,\n",
       "       11736, 12977,   141,   658,    35,     5,     8,    93,    32,\n",
       "          51,    13,    15,    68,    31,   272,    25,  3169,  7846,\n",
       "       10911, 10946,  5999,  9869,  1127,   716,   462,   374,   381,\n",
       "          74,  2227,  8281, 10204, 10224,  6143])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts of NaN in test data\n",
    "test[missColTe].isnull().sum().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 123 columns with NaN are the same in train and test data\n",
    "set(missColTr).symmetric_difference(set(missColTe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'LN2_RIndLngBEOth', u'LN2_WIndLngBEOth'], dtype='object')\n",
      "Index([u'LN2_RIndLngBEOth', u'LN2_WIndLngBEOth'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Variables that contain strings\n",
    "print train.columns[train.dtypes==object]\n",
    "print test.columns[test.dtypes==object]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LN2_RIndLngBEOth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hindi                        5198\n",
       "Marathi                      1023\n",
       "Tamil                         941\n",
       "Telugu                        914\n",
       "Bengali                       891\n",
       "Oriya                         478\n",
       "Gujarati                      410\n",
       "Kannada                       399\n",
       "Malayalam                     293\n",
       "Punjabi                       194\n",
       "Assamese                      180\n",
       "Marathi & Hindi                85\n",
       "English                        43\n",
       "Urdu                           39\n",
       "Manipuri                       36\n",
       "Chattisgari                    31\n",
       "None                           21\n",
       "Rajasthani                     21\n",
       "Konkani                        13\n",
       "Tribal Language                12\n",
       "Bhojpuri                       11\n",
       "Hindi & Marathi                11\n",
       "Nepali                         10\n",
       "Mewari                         10\n",
       "Thadou                         10\n",
       "Hindi & Urdu                    7\n",
       "Hindi & Rajasthani              6\n",
       "Govan                           6\n",
       "Karbi                           5\n",
       "sanskrit                        3\n",
       "Punjabi & Hindi                 3\n",
       "HIndi                           3\n",
       "Haryanvi                        2\n",
       "Telugu & Kannada                2\n",
       "Marathi & Kannada               2\n",
       "Kannada & Telugu                2\n",
       "Hindi & Punjabi                 2\n",
       "Hindi & Oriya                   2\n",
       "Urdu, Kannada & Hindi           2\n",
       "Gujarati & Marathi              2\n",
       "Kannada & Urdu                  2\n",
       "Sanskrit                        1\n",
       "Arbi                            1\n",
       "Dehati                          1\n",
       "Hindi & Gujarati                1\n",
       "Santhali                        1\n",
       "Kokborok                        1\n",
       "Meitei                          1\n",
       "Konkani & Hindi                 1\n",
       "Hindi & Kannada                 1\n",
       "Assamese and Hindi              1\n",
       "Rabha                           1\n",
       "Oriya & Hindi                   1\n",
       "Aadiwasi                        1\n",
       "Hindi, Oriya & Bengali          1\n",
       "Hindi, Marathi & Gujarati       1\n",
       "Oriya, Hindi & Bengali          1\n",
       "Name: LN2_RIndLngBEOth, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency table\n",
    "train[\"LN2_RIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all strings to lower case to solve Hindi vs HIndi issue\n",
    "train[\"LN2_RIndLngBEOth\"] = train[\"LN2_RIndLngBEOth\"].str.lower()\n",
    "train[\"LN2_WIndLngBEOth\"] = train[\"LN2_WIndLngBEOth\"].str.lower()\n",
    "test[\"LN2_RIndLngBEOth\"] = test[\"LN2_RIndLngBEOth\"].str.lower()\n",
    "test[\"LN2_WIndLngBEOth\"] = test[\"LN2_WIndLngBEOth\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyanair/.pyenv/versions/2.7.14/envs/interview_env/lib/python2.7/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# If multiple languages listed, coalesce to the one with highest frequency\n",
    "train[\"LN2_RIndLngBEOth\"].loc[train[\"LN2_RIndLngBEOth\"].str.contains(\"hindi\", na=False)] = \"hindi\"\n",
    "train[\"LN2_RIndLngBEOth\"].loc[train[\"LN2_RIndLngBEOth\"].str.contains(\"marathi\", na=False)] = \"marathi\"\n",
    "train[\"LN2_RIndLngBEOth\"].loc[train[\"LN2_RIndLngBEOth\"].str.contains(\"kannada\", na=False)] = \"kannada\"\n",
    "# train[\"LN2_RIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"LN2_RIndLngBEOth\"].loc[test[\"LN2_RIndLngBEOth\"].str.contains(\"hindi\", na=False)] = \"hindi\"\n",
    "test[\"LN2_RIndLngBEOth\"].loc[test[\"LN2_RIndLngBEOth\"].str.contains(\"marathi\", na=False)] = \"marathi\"\n",
    "test[\"LN2_RIndLngBEOth\"].loc[test[\"LN2_RIndLngBEOth\"].str.contains(\"tamil\", na=False)] = \"tamil\"\n",
    "test[\"LN2_RIndLngBEOth\"].loc[test[\"LN2_RIndLngBEOth\"].str.contains(\"kannada\", na=False)] = \"kannada\"\n",
    "# test[\"LN2_RIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hindi        5327\n",
       "marathi      1027\n",
       "tamil         941\n",
       "telugu        914\n",
       "bengali       891\n",
       "oriya         478\n",
       "gujarati      410\n",
       "kannada       405\n",
       "malayalam     293\n",
       "other         281\n",
       "punjabi       194\n",
       "assamese      180\n",
       "Name: LN2_RIndLngBEOth, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coalesce languages with frequency <100, into 'other' category\n",
    "# This takes care of test data having languages that train data doesn't have\n",
    "readTr = train[\"LN2_RIndLngBEOth\"].value_counts()\n",
    "train[\"LN2_RIndLngBEOth\"].replace(readTr[readTr<=100].index, \"other\", inplace=True)\n",
    "train[\"LN2_RIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hindi        7847\n",
       "marathi      1641\n",
       "tamil        1455\n",
       "telugu       1406\n",
       "bengali      1360\n",
       "oriya         685\n",
       "gujarati      665\n",
       "kannada       589\n",
       "other         455\n",
       "malayalam     453\n",
       "punjabi       273\n",
       "assamese      252\n",
       "Name: LN2_RIndLngBEOth, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readTe = test[\"LN2_RIndLngBEOth\"].value_counts()\n",
    "test[\"LN2_RIndLngBEOth\"].replace(readTe[readTe<=100].index, \"other\", inplace=True)\n",
    "test[\"LN2_RIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Languages in test data that are NOT in train data\n",
    "set(test[\"LN2_RIndLngBEOth\"]) - set(train[\"LN2_RIndLngBEOth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LN2_WIndLngBEOth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"LN2_WIndLngBEOth\"].loc[train[\"LN2_WIndLngBEOth\"].str.contains(\"hindi\", na=False)] = \"hindi\"\n",
    "train[\"LN2_WIndLngBEOth\"].loc[train[\"LN2_WIndLngBEOth\"].str.contains(\"kannada\", na=False)] = \"kannada\"\n",
    "train[\"LN2_WIndLngBEOth\"].loc[train[\"LN2_WIndLngBEOth\"].str.contains(\"marathi\", na=False)] = \"marathi\"\n",
    "# train[\"LN2_WIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"LN2_WIndLngBEOth\"].loc[test[\"LN2_WIndLngBEOth\"].str.contains(\"hindi\", na=False)] = \"hindi\"\n",
    "test[\"LN2_WIndLngBEOth\"].loc[test[\"LN2_WIndLngBEOth\"].str.contains(\"marathi\", na=False)] = \"marathi\"\n",
    "test[\"LN2_WIndLngBEOth\"].loc[test[\"LN2_WIndLngBEOth\"].str.contains(\"telugu\", na=False)] = \"telugu\"\n",
    "test[\"LN2_WIndLngBEOth\"].loc[test[\"LN2_WIndLngBEOth\"].str.contains(\"tamil\", na=False)] = \"tamil\"\n",
    "# test[\"LN2_WIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hindi        5380\n",
       "bengali      1083\n",
       "tamil         949\n",
       "telugu        895\n",
       "marathi       834\n",
       "oriya         504\n",
       "gujarati      469\n",
       "kannada       419\n",
       "other         293\n",
       "malayalam     255\n",
       "assamese      134\n",
       "punjabi       129\n",
       "Name: LN2_WIndLngBEOth, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeTr = train[\"LN2_WIndLngBEOth\"].value_counts()\n",
    "train[\"LN2_WIndLngBEOth\"].replace(writeTr[writeTr<=100].index, \"other\", inplace=True)\n",
    "train[\"LN2_WIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hindi        7966\n",
       "bengali      1691\n",
       "tamil        1466\n",
       "telugu       1397\n",
       "marathi      1382\n",
       "oriya         710\n",
       "gujarati      688\n",
       "kannada       587\n",
       "malayalam     396\n",
       "other         391\n",
       "punjabi       197\n",
       "assamese      190\n",
       "Name: LN2_WIndLngBEOth, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeTe = test[\"LN2_WIndLngBEOth\"].value_counts()\n",
    "test[\"LN2_WIndLngBEOth\"].replace(writeTe[writeTe<=100].index, \"other\", inplace=True)\n",
    "test[\"LN2_WIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test[\"LN2_WIndLngBEOth\"]) - set(train[\"LN2_WIndLngBEOth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Strings to Float\n",
    "\n",
    "Sklearn requires strings to be converted to floats. One such way to do it is to use the pd.factorize() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the Imputer only accepts numeric data, fill missing languages with Hindi and \n",
    "# then convert those strings to float\n",
    "train[\"LN2_RIndLngBEOth\"].fillna(\"hindi\", inplace=True)\n",
    "train[\"LN2_WIndLngBEOth\"].fillna(\"hindi\", inplace=True)\n",
    "test[\"LN2_RIndLngBEOth\"].fillna(\"hindi\", inplace=True)\n",
    "test[\"LN2_WIndLngBEOth\"].fillna(\"hindi\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change strings to digit keys\n",
    "train[\"LN2_R\"] = pd.factorize(train[\"LN2_RIndLngBEOth\"])[0]\n",
    "train[\"LN2_W\"] = pd.factorize(train[\"LN2_WIndLngBEOth\"])[0]\n",
    "test[\"LN2_R\"] = pd.factorize(test[\"LN2_RIndLngBEOth\"])[0]\n",
    "test[\"LN2_W\"] = pd.factorize(test[\"LN2_WIndLngBEOth\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12 keys for 12 languages\n",
    "test[\"LN2_W\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Impute NaNs\n",
    "\n",
    "Algorithms in Sklearn can't handle NaNs, so impute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>DG4</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "      <th>LN2_R</th>\n",
       "      <th>LN2_W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA6     AA7  AA14  AA15   DG1  DG3  DG3A  DG4  ...    LN2_2  \\\n",
       "0    3   32  NaN  323011  3854   481  1975    3     4    5  ...        1   \n",
       "1    2   26  8.0  268131  2441   344  1981    8     4    5  ...        1   \n",
       "2    1   16  7.0  167581   754   143  1995    3     2    2  ...        1   \n",
       "3    4   44  NaN  445071  5705   604  1980    3     4    5  ...        1   \n",
       "4    4   43  6.0  436161  5645   592  1958    3     4    6  ...        4   \n",
       "\n",
       "   LN2_3  LN2_4   GN1  GN2  GN3  GN4  GN5  LN2_R  LN2_W  \n",
       "0      1      1  99.0   99   99   99   99      0      0  \n",
       "1      3      4   NaN    1    2    2    2      1      1  \n",
       "2      2      2   1.0    2    2    2    2      0      0  \n",
       "3      4      5   NaN    2    2   99   99      2      2  \n",
       "4      4      4   NaN    1    1    1    1      3      3  \n",
       "\n",
       "[5 rows x 360 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data predictors\n",
    "xTr = train.loc[:, ~train.columns.isin([\"is_female\", \"LN2_RIndLngBEOth\", \"LN2_WIndLngBEOth\"])]\n",
    "xTr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>DG4</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "      <th>LN2_R</th>\n",
       "      <th>LN2_W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>7.0</td>\n",
       "      <td>417211</td>\n",
       "      <td>4479</td>\n",
       "      <td>535</td>\n",
       "      <td>1979</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322011</td>\n",
       "      <td>3803</td>\n",
       "      <td>476</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365011</td>\n",
       "      <td>5610</td>\n",
       "      <td>585</td>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>7.0</td>\n",
       "      <td>247061</td>\n",
       "      <td>2550</td>\n",
       "      <td>350</td>\n",
       "      <td>1991</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>8.0</td>\n",
       "      <td>358071</td>\n",
       "      <td>3233</td>\n",
       "      <td>400</td>\n",
       "      <td>1985</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA6     AA7  AA14  AA15   DG1  DG3  DG3A  DG4  ...    LN2_2  \\\n",
       "0    4   41  7.0  417211  4479   535  1979    8     1    1  ...        1   \n",
       "1    3   32  NaN  322011  3803   476  1993    1     4    6  ...        5   \n",
       "2    3   36  NaN  365011  5610   585  1980    3    99    6  ...        5   \n",
       "3    2   24  7.0  247061  2550   350  1991    3     2    1  ...        1   \n",
       "4    3   35  8.0  358071  3233   400  1985    3     4    6  ...        1   \n",
       "\n",
       "   LN2_3  LN2_4  GN1  GN2  GN3  GN4  GN5  LN2_R  LN2_W  \n",
       "0      1      1  2.0    1    3    3    3      0      0  \n",
       "1      5      5  1.0    1    1    1    1      1      0  \n",
       "2      5      5  2.0    2    2    2    2      2      1  \n",
       "3      1      1  2.0    2    2    2    2      0      0  \n",
       "4      1      1  1.0    1    1    1    1      0      0  \n",
       "\n",
       "[5 rows x 360 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data predictors\n",
    "xTe = test.loc[:, ~test.columns.isin([\"is_female\", \"LN2_RIndLngBEOth\", \"LN2_WIndLngBEOth\"])]\n",
    "xTe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since all data are categorical, replace NaNs with the most frequent levels\n",
    "imputer = Imputer(missing_values=\"NaN\", strategy=\"most_frequent\", axis=0, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = imputer.fit_transform(xTr)\n",
    "xTest = imputer.fit_transform(xTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>DG4</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "      <th>LN2_R</th>\n",
       "      <th>LN2_W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>323011.0</td>\n",
       "      <td>3854.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131.0</td>\n",
       "      <td>2441.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>445071.0</td>\n",
       "      <td>5705.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161.0</td>\n",
       "      <td>5645.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3   AA4  AA6       AA7    AA14   AA15     DG1  DG3  DG3A  DG4  ...    \\\n",
       "0  3.0  32.0  6.0  323011.0  3854.0  481.0  1975.0  3.0   4.0  5.0  ...     \n",
       "1  2.0  26.0  8.0  268131.0  2441.0  344.0  1981.0  8.0   4.0  5.0  ...     \n",
       "2  1.0  16.0  7.0  167581.0   754.0  143.0  1995.0  3.0   2.0  2.0  ...     \n",
       "3  4.0  44.0  6.0  445071.0  5705.0  604.0  1980.0  3.0   4.0  5.0  ...     \n",
       "4  4.0  43.0  6.0  436161.0  5645.0  592.0  1958.0  3.0   4.0  6.0  ...     \n",
       "\n",
       "   LN2_2  LN2_3  LN2_4   GN1   GN2   GN3   GN4   GN5  LN2_R  LN2_W  \n",
       "0    1.0    1.0    1.0  99.0  99.0  99.0  99.0  99.0    0.0    0.0  \n",
       "1    1.0    3.0    4.0   1.0   1.0   2.0   2.0   2.0    1.0    1.0  \n",
       "2    1.0    2.0    2.0   1.0   2.0   2.0   2.0   2.0    0.0    0.0  \n",
       "3    1.0    4.0    5.0   1.0   2.0   2.0  99.0  99.0    2.0    2.0  \n",
       "4    4.0    4.0    4.0   1.0   1.0   1.0   1.0   1.0    3.0    3.0  \n",
       "\n",
       "[5 rows x 360 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imputed train data predictors\n",
    "xTrain = pd.DataFrame(xTrain, columns=list(xTr))\n",
    "xTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>DG4</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "      <th>LN2_R</th>\n",
       "      <th>LN2_W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>417211.0</td>\n",
       "      <td>4479.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>322011.0</td>\n",
       "      <td>3803.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>365011.0</td>\n",
       "      <td>5610.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>247061.0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>358071.0</td>\n",
       "      <td>3233.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3   AA4  AA6       AA7    AA14   AA15     DG1  DG3  DG3A  DG4  ...    \\\n",
       "0  4.0  41.0  7.0  417211.0  4479.0  535.0  1979.0  8.0   1.0  1.0  ...     \n",
       "1  3.0  32.0  6.0  322011.0  3803.0  476.0  1993.0  1.0   4.0  6.0  ...     \n",
       "2  3.0  36.0  6.0  365011.0  5610.0  585.0  1980.0  3.0  99.0  6.0  ...     \n",
       "3  2.0  24.0  7.0  247061.0  2550.0  350.0  1991.0  3.0   2.0  1.0  ...     \n",
       "4  3.0  35.0  8.0  358071.0  3233.0  400.0  1985.0  3.0   4.0  6.0  ...     \n",
       "\n",
       "   LN2_2  LN2_3  LN2_4  GN1  GN2  GN3  GN4  GN5  LN2_R  LN2_W  \n",
       "0    1.0    1.0    1.0  2.0  1.0  3.0  3.0  3.0    0.0    0.0  \n",
       "1    5.0    5.0    5.0  1.0  1.0  1.0  1.0  1.0    1.0    0.0  \n",
       "2    5.0    5.0    5.0  2.0  2.0  2.0  2.0  2.0    2.0    1.0  \n",
       "3    1.0    1.0    1.0  2.0  2.0  2.0  2.0  2.0    0.0    0.0  \n",
       "4    1.0    1.0    1.0  1.0  1.0  1.0  1.0  1.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 360 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imputed test data predictors\n",
    "xTest = pd.DataFrame(xTest, columns=list(xTe))\n",
    "xTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# No more NaNs\n",
    "print xTrain.columns[xTrain.isnull().sum()>0]\n",
    "print xTest.columns[xTest.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Run Classification Models\n",
    "\n",
    "## 1. Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: is_female, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data response\n",
    "yTrain = train[\"is_female\"]\n",
    "yTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf =  RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataset with 50% split\n",
    "xTrainVal, xTestVal, yTrainVal, yTestVal = train_test_split(xTrain, yTrain, test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on validation train data\n",
    "rf.fit(X=xTrainVal, y=yTrainVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation test data\n",
    "yPredVal = rf.predict(xTestVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3696,  527],\n",
       "       [ 527, 4378]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix. More diagonal entries - good!\n",
    "confusion_matrix(yTestVal, yPredVal, labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88      4223\n",
      "          1       0.89      0.89      0.89      4905\n",
      "\n",
      "avg / total       0.88      0.88      0.88      9128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTestVal, yPredVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true positive rate (Precision) is 89% for each category. The Random Forest model correctly classifies 3688 out of 4230 males and 4396 out of 4898 females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0972, 'DL0'),\n",
       " (0.0971, 'DG6'),\n",
       " (0.0576, 'DL1'),\n",
       " (0.0557, 'MT1A'),\n",
       " (0.0253, 'FL4'),\n",
       " (0.0239, 'GN5'),\n",
       " (0.0201, 'DG3'),\n",
       " (0.0191, 'GN4'),\n",
       " (0.0159, 'DG1'),\n",
       " (0.0149, 'MT10'),\n",
       " (0.0149, 'GN2'),\n",
       " (0.0137, 'MT2'),\n",
       " (0.0123, 'GN3'),\n",
       " (0.0118, 'DG4'),\n",
       " (0.0115, 'DG8a'),\n",
       " (0.0115, 'AA14'),\n",
       " (0.0109, 'AA7'),\n",
       " (0.0108, 'DL5'),\n",
       " (0.0107, 'AA15'),\n",
       " (0.0078, 'DG5_4'),\n",
       " (0.0077, 'DL14'),\n",
       " (0.0073, 'GN1'),\n",
       " (0.0073, 'AA4'),\n",
       " (0.0061, 'DG9a'),\n",
       " (0.006, 'FL10'),\n",
       " (0.0057, 'FB20'),\n",
       " (0.0057, 'DL24'),\n",
       " (0.0055, 'LN1A'),\n",
       " (0.0055, 'IFI14_2'),\n",
       " (0.0053, 'FL9B'),\n",
       " (0.0051, 'MT17_3'),\n",
       " (0.005, 'MT1'),\n",
       " (0.005, 'FF2A'),\n",
       " (0.0049, 'DL15'),\n",
       " (0.0048, 'IFI14_1'),\n",
       " (0.0048, 'FL9A'),\n",
       " (0.0047, 'IFI16_2'),\n",
       " (0.0046, 'LN2_1'),\n",
       " (0.0046, 'IFI15_2'),\n",
       " (0.0045, 'LN1B'),\n",
       " (0.0043, 'FL9C'),\n",
       " (0.0043, 'FL8_1'),\n",
       " (0.0042, 'IFI17_1'),\n",
       " (0.0042, 'IFI16_1'),\n",
       " (0.0042, 'IFI15_1'),\n",
       " (0.0041, 'LN2_3'),\n",
       " (0.0041, 'FL8_7'),\n",
       " (0.0041, 'FL8_5'),\n",
       " (0.004, 'LN2_2'),\n",
       " (0.004, 'FL8_2'),\n",
       " (0.004, 'FL11'),\n",
       " (0.0039, 'LN2_4'),\n",
       " (0.0039, 'FL8_4'),\n",
       " (0.0039, 'FL8_3'),\n",
       " (0.0038, 'IFI24'),\n",
       " (0.0038, 'FL8_6'),\n",
       " (0.0038, 'FL3'),\n",
       " (0.0038, 'DL4_6'),\n",
       " (0.0037, 'MT7'),\n",
       " (0.0037, 'FF9'),\n",
       " (0.0035, 'DL4_5'),\n",
       " (0.0035, 'DG8b'),\n",
       " (0.0034, 'IFI17_2'),\n",
       " (0.0033, 'MT18_4'),\n",
       " (0.0033, 'MT18_1'),\n",
       " (0.0033, 'LN2_W'),\n",
       " (0.0033, 'FL15'),\n",
       " (0.0033, 'FB19'),\n",
       " (0.0033, 'DG8c'),\n",
       " (0.0033, 'AA3'),\n",
       " (0.0032, 'LN2_R'),\n",
       " (0.0032, 'FB13'),\n",
       " (0.0031, 'MT18_8'),\n",
       " (0.0031, 'FL1'),\n",
       " (0.003, 'MT17_5'),\n",
       " (0.0029, 'FL16'),\n",
       " (0.0028, 'FL17'),\n",
       " (0.0028, 'FB24'),\n",
       " (0.0028, 'FB2'),\n",
       " (0.0028, 'FB18'),\n",
       " (0.0026, 'MT15'),\n",
       " (0.0026, 'DG3A'),\n",
       " (0.0025, 'AA6'),\n",
       " (0.0024, 'MT17_12'),\n",
       " (0.0024, 'IFI14_3'),\n",
       " (0.0023, 'MT17_2'),\n",
       " (0.0023, 'FL2'),\n",
       " (0.0023, 'FL14'),\n",
       " (0.0022, 'MT17_11'),\n",
       " (0.0022, 'MT17_1'),\n",
       " (0.0022, 'IFI18'),\n",
       " (0.0021, 'MT17_6'),\n",
       " (0.0021, 'IFI15_3'),\n",
       " (0.0021, 'IFI14_4'),\n",
       " (0.0021, 'FF6_2'),\n",
       " (0.0021, 'FF10_2'),\n",
       " (0.0021, 'DL4_25'),\n",
       " (0.0021, 'DG5_6'),\n",
       " (0.0021, 'DG5_2'),\n",
       " (0.002, 'MT17_9'),\n",
       " (0.002, 'DG5_7'),\n",
       " (0.0019, 'MT18_2'),\n",
       " (0.0019, 'DL19'),\n",
       " (0.0019, 'DL18'),\n",
       " (0.0018, 'MM1'),\n",
       " (0.0018, 'IFI14_5'),\n",
       " (0.0018, 'FF6_6'),\n",
       " (0.0018, 'FF6_4'),\n",
       " (0.0018, 'FF13'),\n",
       " (0.0018, 'DL6'),\n",
       " (0.0018, 'DL16'),\n",
       " (0.0018, 'DL11'),\n",
       " (0.0017, 'MT17_10'),\n",
       " (0.0017, 'FF6_7'),\n",
       " (0.0017, 'FB1_1'),\n",
       " (0.0017, 'DL4_2'),\n",
       " (0.0017, 'DL23'),\n",
       " (0.0017, 'DL17'),\n",
       " (0.0017, 'DG5_10'),\n",
       " (0.0016, 'IFI15_7'),\n",
       " (0.0016, 'IFI15_4'),\n",
       " (0.0016, 'IFI14_7'),\n",
       " (0.0016, 'FL7_4'),\n",
       " (0.0016, 'FL7_3'),\n",
       " (0.0016, 'FL7_1'),\n",
       " (0.0016, 'FL6_1'),\n",
       " (0.0016, 'FL18'),\n",
       " (0.0016, 'FL13'),\n",
       " (0.0016, 'FF6_8'),\n",
       " (0.0016, 'FF2'),\n",
       " (0.0016, 'FF1'),\n",
       " (0.0016, 'FB3'),\n",
       " (0.0016, 'DL26_12'),\n",
       " (0.0016, 'DL22'),\n",
       " (0.0016, 'DL21'),\n",
       " (0.0016, 'DL20'),\n",
       " (0.0015, 'FL7_2'),\n",
       " (0.0015, 'FL6_3'),\n",
       " (0.0015, 'FF6_9'),\n",
       " (0.0015, 'FF6_5'),\n",
       " (0.0015, 'FF6_3'),\n",
       " (0.0015, 'FF6_1'),\n",
       " (0.0015, 'FF5'),\n",
       " (0.0015, 'FF14_1'),\n",
       " (0.0015, 'FB1_3'),\n",
       " (0.0015, 'FB19B_3'),\n",
       " (0.0015, 'FB19B_1'),\n",
       " (0.0015, 'DG5_5'),\n",
       " (0.0014, 'MT17_4'),\n",
       " (0.0014, 'IFI15_5'),\n",
       " (0.0014, 'FL7_6'),\n",
       " (0.0014, 'FB19B_96'),\n",
       " (0.0014, 'FB19B_4'),\n",
       " (0.0014, 'FB19B_2'),\n",
       " (0.0013, 'MT17_8'),\n",
       " (0.0013, 'FL7_5'),\n",
       " (0.0013, 'FL6_4'),\n",
       " (0.0013, 'FL6_2'),\n",
       " (0.0013, 'FF6_10'),\n",
       " (0.0013, 'FB1_2'),\n",
       " (0.0013, 'DL26_99'),\n",
       " (0.0013, 'DL25_3'),\n",
       " (0.0013, 'DG5_1'),\n",
       " (0.0012, 'IFI3_3'),\n",
       " (0.0012, 'IFI14_6'),\n",
       " (0.0012, 'FL12'),\n",
       " (0.0012, 'FB22_8'),\n",
       " (0.0012, 'FB22_1'),\n",
       " (0.0012, 'FB19B_5'),\n",
       " (0.0012, 'DL26_5'),\n",
       " (0.0012, 'DL25_1'),\n",
       " (0.0011, 'MT18_5'),\n",
       " (0.0011, 'IFI1_3'),\n",
       " (0.0011, 'IFI15_6'),\n",
       " (0.0011, 'DL25_2'),\n",
       " (0.001, 'MT18_3'),\n",
       " (0.001, 'FB16_8'),\n",
       " (0.001, 'DL25_5'),\n",
       " (0.0009, 'MT17_13'),\n",
       " (0.0009, 'FF7_4'),\n",
       " (0.0009, 'FF14_2'),\n",
       " (0.0009, 'FF10_1'),\n",
       " (0.0009, 'DL25_8'),\n",
       " (0.0009, 'DL25_4'),\n",
       " (0.0008, 'MT17_7'),\n",
       " (0.0008, 'FB27_2'),\n",
       " (0.0008, 'FB16_7'),\n",
       " (0.0008, 'FB16_1'),\n",
       " (0.0008, 'DL4_3'),\n",
       " (0.0008, 'DL4_17'),\n",
       " (0.0008, 'DL26_1'),\n",
       " (0.0008, 'DL25_7'),\n",
       " (0.0007, 'FB22_9'),\n",
       " (0.0007, 'DL4_19'),\n",
       " (0.0007, 'DL4_16'),\n",
       " (0.0007, 'DL26_3'),\n",
       " (0.0007, 'DL25_6'),\n",
       " (0.0006, 'FF7_2'),\n",
       " (0.0006, 'FB29_1'),\n",
       " (0.0006, 'FB16_6'),\n",
       " (0.0005, 'MM3_2'),\n",
       " (0.0005, 'IFI1_5'),\n",
       " (0.0005, 'FF7_5'),\n",
       " (0.0005, 'FB29_3'),\n",
       " (0.0005, 'FB22_12'),\n",
       " (0.0005, 'DL4_7'),\n",
       " (0.0005, 'DL4_20'),\n",
       " (0.0005, 'DL4_1'),\n",
       " (0.0005, 'DL26_6'),\n",
       " (0.0005, 'DG5_11'),\n",
       " (0.0004, 'MM2_2'),\n",
       " (0.0004, 'IFI3_1'),\n",
       " (0.0004, 'FF7_1'),\n",
       " (0.0004, 'FF19_6'),\n",
       " (0.0004, 'FF19_4'),\n",
       " (0.0004, 'FF19_1'),\n",
       " (0.0004, 'FB29_2'),\n",
       " (0.0004, 'FB22_10'),\n",
       " (0.0004, 'FB19A_4'),\n",
       " (0.0004, 'FB19A_3'),\n",
       " (0.0004, 'FB19A_2'),\n",
       " (0.0004, 'FB19A_1'),\n",
       " (0.0004, 'DL4_4'),\n",
       " (0.0004, 'DL4_18'),\n",
       " (0.0004, 'DL26_9'),\n",
       " (0.0004, 'DG5_3'),\n",
       " (0.0003, 'MMP1_1'),\n",
       " (0.0003, 'MM3_13'),\n",
       " (0.0003, 'MM3_1'),\n",
       " (0.0003, 'IFI3_2'),\n",
       " (0.0003, 'IFI1_7'),\n",
       " (0.0003, 'IFI1_2'),\n",
       " (0.0003, 'IFI1_1'),\n",
       " (0.0003, 'FF19_3'),\n",
       " (0.0003, 'FF19_2'),\n",
       " (0.0003, 'FF14_23'),\n",
       " (0.0003, 'FF14_11'),\n",
       " (0.0003, 'FB27_3'),\n",
       " (0.0003, 'FB27_1'),\n",
       " (0.0003, 'FB19A_5'),\n",
       " (0.0003, 'DL4_24'),\n",
       " (0.0003, 'DL26_8'),\n",
       " (0.0003, 'DL26_7'),\n",
       " (0.0003, 'DL26_4'),\n",
       " (0.0003, 'DL26_2'),\n",
       " (0.0003, 'DG5_8'),\n",
       " (0.0002, 'MT18_96'),\n",
       " (0.0002, 'FF19_8'),\n",
       " (0.0002, 'FF19_7'),\n",
       " (0.0002, 'FF19_5'),\n",
       " (0.0002, 'FF14_9'),\n",
       " (0.0002, 'FF14_4'),\n",
       " (0.0002, 'FF14_20'),\n",
       " (0.0002, 'FF14_16'),\n",
       " (0.0002, 'FF10_3'),\n",
       " (0.0002, 'FB29_6'),\n",
       " (0.0002, 'FB29_5'),\n",
       " (0.0002, 'FB27_9'),\n",
       " (0.0002, 'FB27_4'),\n",
       " (0.0002, 'FB22_3'),\n",
       " (0.0002, 'FB22_11'),\n",
       " (0.0002, 'FB16_2'),\n",
       " (0.0002, 'DL4_9'),\n",
       " (0.0002, 'DL4_23'),\n",
       " (0.0002, 'DL4_14'),\n",
       " (0.0002, 'DL4_10'),\n",
       " (0.0001, 'MMP1_3'),\n",
       " (0.0001, 'MM3_6'),\n",
       " (0.0001, 'MM3_5'),\n",
       " (0.0001, 'MM3_14'),\n",
       " (0.0001, 'MM2_13'),\n",
       " (0.0001, 'MM2_1'),\n",
       " (0.0001, 'IFI1_9'),\n",
       " (0.0001, 'IFI1_8'),\n",
       " (0.0001, 'IFI1_6'),\n",
       " (0.0001, 'FF7_7'),\n",
       " (0.0001, 'FF7_6'),\n",
       " (0.0001, 'FF7_3'),\n",
       " (0.0001, 'FF14_6'),\n",
       " (0.0001, 'FF14_5'),\n",
       " (0.0001, 'FF14_3'),\n",
       " (0.0001, 'FF14_18'),\n",
       " (0.0001, 'FF14_17'),\n",
       " (0.0001, 'FF14_15'),\n",
       " (0.0001, 'FF14_12'),\n",
       " (0.0001, 'FF14_10'),\n",
       " (0.0001, 'FF10_6'),\n",
       " (0.0001, 'FF10_5'),\n",
       " (0.0001, 'FF10_4'),\n",
       " (0.0001, 'FB29_96'),\n",
       " (0.0001, 'FB29_4'),\n",
       " (0.0001, 'FB27_7'),\n",
       " (0.0001, 'FB27_6'),\n",
       " (0.0001, 'FB22_4'),\n",
       " (0.0001, 'FB22_2'),\n",
       " (0.0001, 'FB19A_96'),\n",
       " (0.0001, 'FB16_96'),\n",
       " (0.0001, 'FB16_3'),\n",
       " (0.0001, 'DL4_8'),\n",
       " (0.0001, 'DL4_22'),\n",
       " (0.0001, 'DL4_21'),\n",
       " (0.0001, 'DL4_13'),\n",
       " (0.0001, 'DL4_12'),\n",
       " (0.0001, 'DL4_11'),\n",
       " (0.0001, 'DL26_10'),\n",
       " (0.0001, 'DG5_9'),\n",
       " (0.0, 'MT18_6'),\n",
       " (0.0, 'MMP1_96'),\n",
       " (0.0, 'MMP1_9'),\n",
       " (0.0, 'MMP1_8'),\n",
       " (0.0, 'MMP1_7'),\n",
       " (0.0, 'MMP1_6'),\n",
       " (0.0, 'MMP1_5'),\n",
       " (0.0, 'MMP1_4'),\n",
       " (0.0, 'MMP1_2'),\n",
       " (0.0, 'MMP1_11'),\n",
       " (0.0, 'MMP1_10'),\n",
       " (0.0, 'MM3_9'),\n",
       " (0.0, 'MM3_8'),\n",
       " (0.0, 'MM3_7'),\n",
       " (0.0, 'MM3_4'),\n",
       " (0.0, 'MM3_3'),\n",
       " (0.0, 'MM3_12'),\n",
       " (0.0, 'MM3_11'),\n",
       " (0.0, 'MM3_10'),\n",
       " (0.0, 'MM2_9'),\n",
       " (0.0, 'MM2_8'),\n",
       " (0.0, 'MM2_7'),\n",
       " (0.0, 'MM2_6'),\n",
       " (0.0, 'MM2_5'),\n",
       " (0.0, 'MM2_4'),\n",
       " (0.0, 'MM2_3'),\n",
       " (0.0, 'MM2_16'),\n",
       " (0.0, 'MM2_15'),\n",
       " (0.0, 'MM2_14'),\n",
       " (0.0, 'MM2_12'),\n",
       " (0.0, 'MM2_11'),\n",
       " (0.0, 'MM2_10'),\n",
       " (0.0, 'IFI1_4'),\n",
       " (0.0, 'FF7_96'),\n",
       " (0.0, 'FF14_96'),\n",
       " (0.0, 'FF14_8'),\n",
       " (0.0, 'FF14_7'),\n",
       " (0.0, 'FF14_22'),\n",
       " (0.0, 'FF14_21'),\n",
       " (0.0, 'FF14_19'),\n",
       " (0.0, 'FF14_14'),\n",
       " (0.0, 'FF14_13'),\n",
       " (0.0, 'FF10_96'),\n",
       " (0.0, 'FB27_96'),\n",
       " (0.0, 'FB27_8'),\n",
       " (0.0, 'FB27_5'),\n",
       " (0.0, 'FB22_96'),\n",
       " (0.0, 'FB22_7'),\n",
       " (0.0, 'FB22_6'),\n",
       " (0.0, 'FB22_5'),\n",
       " (0.0, 'FB16_5'),\n",
       " (0.0, 'FB16_4'),\n",
       " (0.0, 'DL4_15'),\n",
       " (0.0, 'DG5_96')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable importance\n",
    "sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), xTrain.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "yTest = rf.predict(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write prediction to CSV file\n",
    "submissionRF = pd.DataFrame({\"test_id\": range(0, len(yTest)), \"is_female\": yTest})\n",
    "submissionRF = submissionRF[[\"test_id\", \"is_female\"]]\n",
    "submissionRF.to_csv(\"../submission/submissionRF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model yielded **ROC score of 0.88142** on Kaggle submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
