{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>DG3</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  is_female  DG3     ...      \\\n",
       "0    3   32  3.0  NaN  323011  3854   481  1975          1    3     ...       \n",
       "1    2   26  NaN  8.0  268131  2441   344  1981          1    8     ...       \n",
       "2    1   16  NaN  7.0  167581   754   143  1995          1    3     ...       \n",
       "3    4   44  5.0  NaN  445071  5705   604  1980          1    3     ...       \n",
       "4    4   43  NaN  6.0  436161  5645   592  1958          1    3     ...       \n",
       "\n",
       "    GN1 GN1_OTHERS  GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  GN4_OTHERS  GN5  \\\n",
       "0  99.0        NaN   99         NaN   99         NaN   99         NaN   99   \n",
       "1   NaN        NaN    1         NaN    2         NaN    2         NaN    2   \n",
       "2   1.0        NaN    2         NaN    2         NaN    2         NaN    2   \n",
       "3   NaN        NaN    2         NaN    2         NaN   99         NaN   99   \n",
       "4   NaN        NaN    1         NaN    1         NaN    1         NaN    1   \n",
       "\n",
       "   GN5_OTHERS  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 1234 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\", low_memory=False)\n",
    "train.drop([\"train_id\"], axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18255, 1234)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data dimensions\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>417211</td>\n",
       "      <td>4479</td>\n",
       "      <td>535</td>\n",
       "      <td>1979</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>322011</td>\n",
       "      <td>3803</td>\n",
       "      <td>476</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365011</td>\n",
       "      <td>5610</td>\n",
       "      <td>585</td>\n",
       "      <td>1980</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>247061</td>\n",
       "      <td>2550</td>\n",
       "      <td>350</td>\n",
       "      <td>1991</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>358071</td>\n",
       "      <td>3233</td>\n",
       "      <td>400</td>\n",
       "      <td>1985</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1233 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  DG3  DG3A     ...      GN1  \\\n",
       "0    4   41  NaN  7.0  417211  4479   535  1979    8     1     ...      2.0   \n",
       "1    3   32  2.0  NaN  322011  3803   476  1993    1     4     ...      1.0   \n",
       "2    3   36  5.0  NaN  365011  5610   585  1980    3    99     ...      2.0   \n",
       "3    2   24  NaN  7.0  247061  2550   350  1991    3     2     ...      2.0   \n",
       "4    3   35  NaN  8.0  358071  3233   400  1985    3     4     ...      1.0   \n",
       "\n",
       "   GN1_OTHERS GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  GN4_OTHERS  GN5  \\\n",
       "0         NaN   1         NaN    3         NaN    3         NaN    3   \n",
       "1         NaN   1         NaN    1         NaN    1         NaN    1   \n",
       "2         NaN   2         NaN    2         NaN    2         NaN    2   \n",
       "3         NaN   2         NaN    2         NaN    2         NaN    2   \n",
       "4         NaN   1         NaN    1         NaN    1         NaN    1   \n",
       "\n",
       "   GN5_OTHERS  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 1233 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"../data/test.csv\", low_memory=False)\n",
    "test.drop([\"test_id\"], axis=1, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27285, 1233)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1113"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables listed in the data dictionary\n",
    "var = list(pd.read_excel(\"../data/data-dictionary.xlsx\", \n",
    "                         sheet_name=\"Codebook\")[\"Column Name\"]) + \\\n",
    "      list(pd.read_excel(\"../data/data-dictionary.xlsx\", \n",
    "                         sheet_name=\"AA Locations\", \n",
    "                         header=None)[0].dropna())\n",
    "len(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Discrepancy Between Data and its Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of variables present in train, but NOT present in dictionary (A-B)\n",
    "len(set(train.columns) - set(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables present in test, but NOT present in train (A-B)\n",
    "set(test.columns) - set(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_female'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables present in train, but NOT present in test\n",
    "set(train.columns) - set(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of variables present in dictionary, but NOT present in train\n",
    "len(set(var) - set(train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Discover NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'DG4_OTHERS', u'G2P2_2_OTHERS', u'G2P2_10_OTHERS', u'G2P2_12_OTHERS',\n",
       "       u'G2P2_15_OTHERS', u'MT12_99', u'MT13_4_OTHERS', u'MT13_96_OTHERS',\n",
       "       u'MT14_3_OTHERS', u'MT14_5_OTHERS', u'MT14_7_OTHERS', u'MM3_15',\n",
       "       u'MM3_16', u'MM4_16', u'MM5_4', u'MM5_5', u'MM5_15', u'MM5_16',\n",
       "       u'MM5A_4', u'MM5A_5', u'MM5A_15', u'MM5A_16', u'MM6_16', u'MM7_4',\n",
       "       u'MM7_5', u'MM7_15', u'MM7_16', u'MM8_15', u'MM8_16', u'MM11_4',\n",
       "       u'MM11_5', u'MM11_5_OTHERS', u'MM11_11_OTHERS', u'MM11_15', u'MM11_16',\n",
       "       u'MM15_OTHERS', u'MM17_13', u'MM17_15', u'MM17_17', u'MM17_19',\n",
       "       u'MM17_22', u'MM17_96', u'MM17A', u'MM38_OTHERS', u'MM40_14',\n",
       "       u'MM40_96', u'MMP4_7', u'MMP4_8', u'MMP4_96', u'FB28_3_OTHERS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty columns with no data\n",
    "emptyCol = train.columns[train.isnull().sum()==len(train)]\n",
    "emptyCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18255, 1184)\n",
      "(27285, 1183)\n"
     ]
    }
   ],
   "source": [
    "# Remove empty columns from train and test data\n",
    "train.drop(emptyCol, axis=1, inplace=True)\n",
    "test.drop(emptyCol, axis=1, inplace=True)\n",
    "print train.shape\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'AA5', u'DG3A_OTHERS', u'DG9b', u'DG9c', u'DG10b', u'DG10c', u'DG11b',\n",
       "       u'DG11c', u'DG12B_1', u'DG12B_2',\n",
       "       ...\n",
       "       u'FB28_1_OTHERS', u'FB28_2_OTHERS', u'FB28_4_OTHERS', u'FB28_96_OTHERS',\n",
       "       u'FB29_OTHERS', u'GN1_OTHERS', u'GN2_OTHERS', u'GN3_OTHERS',\n",
       "       u'GN4_OTHERS', u'GN5_OTHERS'],\n",
       "      dtype='object', length=823)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns where atleast 50% of the data are missing\n",
    "sparseCol = train.columns[train.isnull().sum()>=len(train)/2.]\n",
    "sparseCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12602, 18205, 10018, 11451, 11678, 12862, 12002, 13158, 14691,\n",
       "       18246, 17508, 18222, 17974,  9257, 18153, 18021, 17947, 10985,\n",
       "       15815, 18238, 18144, 14264, 14628, 18249, 15645, 18182, 17704,\n",
       "       18232, 18241, 18179, 18235, 18208, 17524, 17965, 17860, 18212,\n",
       "       18011, 18200, 18001, 18251, 18227, 18254, 18253, 18250,  9333,\n",
       "       18244, 18230, 15095, 18240, 12082, 18234, 11243, 18233, 17672,\n",
       "       15596, 17805, 18046, 18218, 18245, 16572, 18247, 18003, 16681,\n",
       "       18055, 18252, 17572, 11285, 14806, 18199, 18135, 11496, 18248,\n",
       "       17876, 18229, 11310,  9987, 18048, 18101, 18155, 18215, 18112,\n",
       "       18133, 18049, 18217, 18124, 18116, 18170, 18242, 18209, 18183,\n",
       "       17788, 17890, 17352, 18169, 18187, 18054, 18198, 18143, 18211,\n",
       "       18194, 18125, 18180, 17752, 18157, 18239, 18223, 18220, 18216,\n",
       "       18236, 18128, 18181, 17182, 18243, 17183, 18204, 18190, 18172,\n",
       "       18191, 18219, 18201, 18224, 18226, 18207, 18210, 18214, 18031,\n",
       "       18225, 18062, 17959, 18015, 17759, 17811, 17381, 17467, 17186,\n",
       "       18213, 17616, 14574, 16325, 16366, 16358, 15388, 16897, 18114,\n",
       "       18126, 13831, 18195, 13723, 18237, 16761, 17997, 18163, 17674,\n",
       "       16691, 15474, 18158, 18192, 17059, 12714, 18160, 18024, 17975,\n",
       "       17792, 17686, 17064,  9917, 18228, 17910, 16813, 17893, 18085,\n",
       "       18189, 18196, 18177])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NaN counts for columns with atleast 50% missing data\n",
    "train[sparseCol].isnull().sum().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18255, 361)\n",
      "(27285, 360)\n"
     ]
    }
   ],
   "source": [
    "# Remove columns with atleast 50% missing data from train and test data\n",
    "train.drop(sparseCol, axis=1, inplace=True)\n",
    "test.drop(sparseCol, axis=1, inplace=True)\n",
    "print train.shape\n",
    "print test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DL14', 'DL4_96', 'DL4_99', 'LN2_RIndLngBEOth', 'LN2_WIndLngBEOth'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variables present in train, but NOT present in data dictionary (A-B)\n",
    "set(train.columns) - set(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the data dictionary:  \n",
    "DL4_96 = DL4_24,  \n",
    "DL4_99 = DL4_25,   \n",
    "LN2_RIndLngBEOth = LN2_3 Reading specification,   \n",
    "LN2_WIndLngBEOth = LN2_4 Writing specification,  \n",
    "DL14 description is unknown\n",
    "\n",
    "Let's rename columns DL4_96 and DL4_99 in train and test data to match with the dictionary labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in train and test data to match with dictionary labels\n",
    "train.rename(columns={\"DL4_96\": \"DL4_24\", \"DL4_99\": \"DL4_25\"}, inplace=True)\n",
    "test.rename(columns={\"DL4_96\": \"DL4_24\", \"DL4_99\": \"DL4_25\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 123 columns have NaN in train data\n",
    "missColTr = train.columns[train.isnull().sum()>0]\n",
    "len(missColTr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5653,  232, 6806,  757, 8922, 7012, 6173, 6759, 6380, 7839, 8670,\n",
       "         86,  425,   37,   11,    6,   47,   21,   10,    7,   34,   20,\n",
       "        159,   16, 2129, 5293, 7319, 7397, 4049, 6580,  769,  444,  297,\n",
       "        247,  263,   63, 1494, 5541, 6914, 6911, 4025])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts of NaN in train data\n",
    "train[missColTr].isnull().sum().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 123 columns have NaN in test data\n",
    "missColTe = test.columns[test.isnull().sum()>0]\n",
    "len(missColTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8459,   386, 10207,  1158, 13479, 10590,  8976, 10134,  9622,\n",
       "       11736, 12977,   141,   658,    35,     5,     8,    93,    32,\n",
       "          51,    13,    15,    68,    31,   272,    25,  3169,  7846,\n",
       "       10911, 10946,  5999,  9869,  1127,   716,   462,   374,   381,\n",
       "          74,  2227,  8281, 10204, 10224,  6143])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts of NaN in test data\n",
    "test[missColTe].isnull().sum().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 123 columns with NaN are the same in train and test data\n",
    "set(missColTr).symmetric_difference(set(missColTe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'LN2_RIndLngBEOth', u'LN2_WIndLngBEOth'], dtype='object')\n",
      "Index([u'LN2_RIndLngBEOth', u'LN2_WIndLngBEOth'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Variables that contain strings\n",
    "print train.columns[train.dtypes==object]\n",
    "print test.columns[test.dtypes==object]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LN2_RIndLngBEOth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hindi                        5198\n",
       "Marathi                      1023\n",
       "Tamil                         941\n",
       "Telugu                        914\n",
       "Bengali                       891\n",
       "Oriya                         478\n",
       "Gujarati                      410\n",
       "Kannada                       399\n",
       "Malayalam                     293\n",
       "Punjabi                       194\n",
       "Assamese                      180\n",
       "Marathi & Hindi                85\n",
       "English                        43\n",
       "Urdu                           39\n",
       "Manipuri                       36\n",
       "Chattisgari                    31\n",
       "None                           21\n",
       "Rajasthani                     21\n",
       "Konkani                        13\n",
       "Tribal Language                12\n",
       "Bhojpuri                       11\n",
       "Hindi & Marathi                11\n",
       "Nepali                         10\n",
       "Mewari                         10\n",
       "Thadou                         10\n",
       "Hindi & Urdu                    7\n",
       "Hindi & Rajasthani              6\n",
       "Govan                           6\n",
       "Karbi                           5\n",
       "sanskrit                        3\n",
       "Punjabi & Hindi                 3\n",
       "HIndi                           3\n",
       "Haryanvi                        2\n",
       "Telugu & Kannada                2\n",
       "Marathi & Kannada               2\n",
       "Kannada & Telugu                2\n",
       "Hindi & Punjabi                 2\n",
       "Hindi & Oriya                   2\n",
       "Urdu, Kannada & Hindi           2\n",
       "Gujarati & Marathi              2\n",
       "Kannada & Urdu                  2\n",
       "Sanskrit                        1\n",
       "Arbi                            1\n",
       "Dehati                          1\n",
       "Hindi & Gujarati                1\n",
       "Santhali                        1\n",
       "Kokborok                        1\n",
       "Meitei                          1\n",
       "Konkani & Hindi                 1\n",
       "Hindi & Kannada                 1\n",
       "Assamese and Hindi              1\n",
       "Rabha                           1\n",
       "Oriya & Hindi                   1\n",
       "Aadiwasi                        1\n",
       "Hindi, Oriya & Bengali          1\n",
       "Hindi, Marathi & Gujarati       1\n",
       "Oriya, Hindi & Bengali          1\n",
       "Name: LN2_RIndLngBEOth, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency table\n",
    "train[\"LN2_RIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all strings to lower case to solve Hindi vs HIndi issue\n",
    "train[\"LN2_RIndLngBEOth\"] = train[\"LN2_RIndLngBEOth\"].str.lower()\n",
    "train[\"LN2_WIndLngBEOth\"] = train[\"LN2_WIndLngBEOth\"].str.lower()\n",
    "test[\"LN2_RIndLngBEOth\"] = test[\"LN2_RIndLngBEOth\"].str.lower()\n",
    "test[\"LN2_WIndLngBEOth\"] = test[\"LN2_WIndLngBEOth\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyanair/.pyenv/versions/2.7.14/envs/interview_env/lib/python2.7/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# If multiple languages listed, coalesce to the one with highest frequency\n",
    "train[\"LN2_RIndLngBEOth\"].loc[train[\"LN2_RIndLngBEOth\"].str.contains(\"hindi\", na=False)] = \"hindi\"\n",
    "train[\"LN2_RIndLngBEOth\"].loc[train[\"LN2_RIndLngBEOth\"].str.contains(\"marathi\", na=False)] = \"marathi\"\n",
    "train[\"LN2_RIndLngBEOth\"].loc[train[\"LN2_RIndLngBEOth\"].str.contains(\"kannada\", na=False)] = \"kannada\"\n",
    "# train[\"LN2_RIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"LN2_RIndLngBEOth\"].loc[test[\"LN2_RIndLngBEOth\"].str.contains(\"hindi\", na=False)] = \"hindi\"\n",
    "test[\"LN2_RIndLngBEOth\"].loc[test[\"LN2_RIndLngBEOth\"].str.contains(\"marathi\", na=False)] = \"marathi\"\n",
    "test[\"LN2_RIndLngBEOth\"].loc[test[\"LN2_RIndLngBEOth\"].str.contains(\"tamil\", na=False)] = \"tamil\"\n",
    "test[\"LN2_RIndLngBEOth\"].loc[test[\"LN2_RIndLngBEOth\"].str.contains(\"kannada\", na=False)] = \"kannada\"\n",
    "# test[\"LN2_RIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hindi        5327\n",
       "marathi      1027\n",
       "tamil         941\n",
       "telugu        914\n",
       "bengali       891\n",
       "oriya         478\n",
       "gujarati      410\n",
       "kannada       405\n",
       "malayalam     293\n",
       "other         281\n",
       "punjabi       194\n",
       "assamese      180\n",
       "Name: LN2_RIndLngBEOth, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coalesce languages with frequency <100, into 'other' category\n",
    "# This takes care of test data having languages that train data doesn't have\n",
    "readTr = train[\"LN2_RIndLngBEOth\"].value_counts()\n",
    "train[\"LN2_RIndLngBEOth\"].replace(readTr[readTr<=100].index, \"other\", inplace=True)\n",
    "train[\"LN2_RIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hindi        7847\n",
       "marathi      1641\n",
       "tamil        1455\n",
       "telugu       1406\n",
       "bengali      1360\n",
       "oriya         685\n",
       "gujarati      665\n",
       "kannada       589\n",
       "other         455\n",
       "malayalam     453\n",
       "punjabi       273\n",
       "assamese      252\n",
       "Name: LN2_RIndLngBEOth, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readTe = test[\"LN2_RIndLngBEOth\"].value_counts()\n",
    "test[\"LN2_RIndLngBEOth\"].replace(readTe[readTe<=100].index, \"other\", inplace=True)\n",
    "test[\"LN2_RIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Languages in test data that are NOT in train data\n",
    "set(test[\"LN2_RIndLngBEOth\"]) - set(train[\"LN2_RIndLngBEOth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LN2_WIndLngBEOth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"LN2_WIndLngBEOth\"].loc[train[\"LN2_WIndLngBEOth\"].str.contains(\"hindi\", na=False)] = \"hindi\"\n",
    "train[\"LN2_WIndLngBEOth\"].loc[train[\"LN2_WIndLngBEOth\"].str.contains(\"kannada\", na=False)] = \"kannada\"\n",
    "train[\"LN2_WIndLngBEOth\"].loc[train[\"LN2_WIndLngBEOth\"].str.contains(\"marathi\", na=False)] = \"marathi\"\n",
    "# train[\"LN2_WIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"LN2_WIndLngBEOth\"].loc[test[\"LN2_WIndLngBEOth\"].str.contains(\"hindi\", na=False)] = \"hindi\"\n",
    "test[\"LN2_WIndLngBEOth\"].loc[test[\"LN2_WIndLngBEOth\"].str.contains(\"marathi\", na=False)] = \"marathi\"\n",
    "test[\"LN2_WIndLngBEOth\"].loc[test[\"LN2_WIndLngBEOth\"].str.contains(\"telugu\", na=False)] = \"telugu\"\n",
    "test[\"LN2_WIndLngBEOth\"].loc[test[\"LN2_WIndLngBEOth\"].str.contains(\"tamil\", na=False)] = \"tamil\"\n",
    "# test[\"LN2_WIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hindi        5380\n",
       "bengali      1083\n",
       "tamil         949\n",
       "telugu        895\n",
       "marathi       834\n",
       "oriya         504\n",
       "gujarati      469\n",
       "kannada       419\n",
       "other         293\n",
       "malayalam     255\n",
       "assamese      134\n",
       "punjabi       129\n",
       "Name: LN2_WIndLngBEOth, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeTr = train[\"LN2_WIndLngBEOth\"].value_counts()\n",
    "train[\"LN2_WIndLngBEOth\"].replace(writeTr[writeTr<=100].index, \"other\", inplace=True)\n",
    "train[\"LN2_WIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hindi        7966\n",
       "bengali      1691\n",
       "tamil        1466\n",
       "telugu       1397\n",
       "marathi      1382\n",
       "oriya         710\n",
       "gujarati      688\n",
       "kannada       587\n",
       "malayalam     396\n",
       "other         391\n",
       "punjabi       197\n",
       "assamese      190\n",
       "Name: LN2_WIndLngBEOth, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeTe = test[\"LN2_WIndLngBEOth\"].value_counts()\n",
    "test[\"LN2_WIndLngBEOth\"].replace(writeTe[writeTe<=100].index, \"other\", inplace=True)\n",
    "test[\"LN2_WIndLngBEOth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test[\"LN2_WIndLngBEOth\"]) - set(train[\"LN2_WIndLngBEOth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Strings to Numbers\n",
    "\n",
    "Most ML algorithms in Sklearn can't handle strings.\n",
    "\n",
    "#### One-Hot Encoding\n",
    "\n",
    "Introduces the curse-of-dimensionality issue. Also, tree-based models usually struggle with deciding the splits in sparse data. Non-tree based models, such as linear models, on the other hand, pick up optimal coefficient for every predictor in sparse data.\n",
    "\n",
    "#### Label Encoding\n",
    "\n",
    "1. **sklearn.preprocessing.LabelEncoder()** assigns numbers to **alphabetically sorted** data. Eg: [C, A, B] -> [3, 1, 2]\n",
    "2. **pandas.factorize()** assigns numbers by **order of appearance**. Eg: [C, A, B] -> [1, 2, 3]\n",
    "\n",
    "factorize() is not a good choice here since languages in RIndLngBEOth and WIndLngBEOth could appear in different order. LabelEncoder() is also not a good choice here since the categories are not ordinal.\n",
    "\n",
    "#### Frequency Encoding\n",
    "\n",
    "Map categorical levels to its frequencies. This is a good choice here. (Note we don't have to worry about breaking ties since no two categories have the same frequency.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the Imputer only accepts numeric data, fill missing languages with Hindi as it is the most frequent language\n",
    "# and then convert those strings to numbers\n",
    "train[\"LN2_RIndLngBEOth\"].fillna(\"hindi\", inplace=True)\n",
    "train[\"LN2_WIndLngBEOth\"].fillna(\"hindi\", inplace=True)\n",
    "test[\"LN2_RIndLngBEOth\"].fillna(\"hindi\", inplace=True)\n",
    "test[\"LN2_WIndLngBEOth\"].fillna(\"hindi\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "# train = train.apply(LabelEncoder().fit_transform)\n",
    "# test = test.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Encoding\n",
    "freqRTr = train.groupby(\"LN2_RIndLngBEOth\").size() / len(train)\n",
    "train[\"LN2_RIndLngBEOth\"] = train[\"LN2_RIndLngBEOth\"].map(freqRTr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqWTr = train.groupby(\"LN2_WIndLngBEOth\").size() / len(train)\n",
    "train[\"LN2_WIndLngBEOth\"] = train[\"LN2_WIndLngBEOth\"].map(freqWTr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqRTe = test.groupby(\"LN2_RIndLngBEOth\").size() / len(test)\n",
    "test[\"LN2_RIndLngBEOth\"] = test[\"LN2_RIndLngBEOth\"].map(freqRTe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqWTe = test.groupby(\"LN2_WIndLngBEOth\").size() / len(test)\n",
    "test[\"LN2_WIndLngBEOth\"] = test[\"LN2_WIndLngBEOth\"].map(freqWTe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Impute NaNs\n",
    "\n",
    "Most ML algorithms in Sklearn can't handle NaNs, so impute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since all data are categorical, replace NaNs with the most frequent levels\n",
    "imputer = Imputer(missing_values=\"NaN\", strategy=\"most_frequent\", axis=0, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>LN2_RIndLngBEOth</th>\n",
       "      <th>LN2_WIndLngBEOth</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>323011.0</td>\n",
       "      <td>3854.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670556</td>\n",
       "      <td>0.673295</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131.0</td>\n",
       "      <td>2441.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.048809</td>\n",
       "      <td>0.059326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.670556</td>\n",
       "      <td>0.673295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>445071.0</td>\n",
       "      <td>5705.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.051548</td>\n",
       "      <td>0.051986</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161.0</td>\n",
       "      <td>5645.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.016050</td>\n",
       "      <td>0.013969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3   AA4  AA6       AA7    AA14   AA15     DG1  is_female  DG3  DG3A  \\\n",
       "0  3.0  32.0  6.0  323011.0  3854.0  481.0  1975.0        1.0  3.0   4.0   \n",
       "1  2.0  26.0  8.0  268131.0  2441.0  344.0  1981.0        1.0  8.0   4.0   \n",
       "2  1.0  16.0  7.0  167581.0   754.0  143.0  1995.0        1.0  3.0   2.0   \n",
       "3  4.0  44.0  6.0  445071.0  5705.0  604.0  1980.0        1.0  3.0   4.0   \n",
       "4  4.0  43.0  6.0  436161.0  5645.0  592.0  1958.0        1.0  3.0   4.0   \n",
       "\n",
       "   ...   LN2_2  LN2_3  LN2_4  LN2_RIndLngBEOth  LN2_WIndLngBEOth   GN1   GN2  \\\n",
       "0  ...     1.0    1.0    1.0          0.670556          0.673295  99.0  99.0   \n",
       "1  ...     1.0    3.0    4.0          0.048809          0.059326   1.0   1.0   \n",
       "2  ...     1.0    2.0    2.0          0.670556          0.673295   1.0   2.0   \n",
       "3  ...     1.0    4.0    5.0          0.051548          0.051986   1.0   2.0   \n",
       "4  ...     4.0    4.0    4.0          0.016050          0.013969   1.0   1.0   \n",
       "\n",
       "    GN3   GN4   GN5  \n",
       "0  99.0  99.0  99.0  \n",
       "1   2.0   2.0   2.0  \n",
       "2   2.0   2.0   2.0  \n",
       "3   2.0  99.0  99.0  \n",
       "4   1.0   1.0   1.0  \n",
       "\n",
       "[5 rows x 361 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute train data\n",
    "cTrain = imputer.fit_transform(train)\n",
    "cTrain = pd.DataFrame(cTrain, columns=list(train))\n",
    "cTrain.to_csv(\"../data/train-cleaned.csv\", index=False)  # write cleaned data to CSV\n",
    "cTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>DG4</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>LN2_RIndLngBEOth</th>\n",
       "      <th>LN2_WIndLngBEOth</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>417211.0</td>\n",
       "      <td>4479.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.661572</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>322011.0</td>\n",
       "      <td>3803.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.024372</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>365011.0</td>\n",
       "      <td>5610.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.060143</td>\n",
       "      <td>0.050651</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>247061.0</td>\n",
       "      <td>2550.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.661572</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>358071.0</td>\n",
       "      <td>3233.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.661572</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3   AA4  AA6       AA7    AA14   AA15     DG1  DG3  DG3A  DG4 ...   \\\n",
       "0  4.0  41.0  7.0  417211.0  4479.0  535.0  1979.0  8.0   1.0  1.0 ...    \n",
       "1  3.0  32.0  6.0  322011.0  3803.0  476.0  1993.0  1.0   4.0  6.0 ...    \n",
       "2  3.0  36.0  6.0  365011.0  5610.0  585.0  1980.0  3.0  99.0  6.0 ...    \n",
       "3  2.0  24.0  7.0  247061.0  2550.0  350.0  1991.0  3.0   2.0  1.0 ...    \n",
       "4  3.0  35.0  8.0  358071.0  3233.0  400.0  1985.0  3.0   4.0  6.0 ...    \n",
       "\n",
       "   LN2_2  LN2_3  LN2_4  LN2_RIndLngBEOth  LN2_WIndLngBEOth  GN1  GN2  GN3  \\\n",
       "0    1.0    1.0    1.0          0.661572          0.666667  2.0  1.0  3.0   \n",
       "1    5.0    5.0    5.0          0.024372          0.666667  1.0  1.0  1.0   \n",
       "2    5.0    5.0    5.0          0.060143          0.050651  2.0  2.0  2.0   \n",
       "3    1.0    1.0    1.0          0.661572          0.666667  2.0  2.0  2.0   \n",
       "4    1.0    1.0    1.0          0.661572          0.666667  1.0  1.0  1.0   \n",
       "\n",
       "   GN4  GN5  \n",
       "0  3.0  3.0  \n",
       "1  1.0  1.0  \n",
       "2  2.0  2.0  \n",
       "3  2.0  2.0  \n",
       "4  1.0  1.0  \n",
       "\n",
       "[5 rows x 360 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute test data\n",
    "cTest = imputer.fit_transform(test)\n",
    "cTest = pd.DataFrame(cTest, columns=list(test))\n",
    "cTest.to_csv(\"../data/test-cleaned.csv\", index=False)\n",
    "cTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# No more NaNs\n",
    "print cTrain.columns[cTrain.isnull().sum()>0]\n",
    "print cTest.columns[cTest.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>DG4</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>LN2_RIndLngBEOth</th>\n",
       "      <th>LN2_WIndLngBEOth</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>323011.0</td>\n",
       "      <td>3854.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670556</td>\n",
       "      <td>0.673295</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131.0</td>\n",
       "      <td>2441.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.048809</td>\n",
       "      <td>0.059326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.670556</td>\n",
       "      <td>0.673295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>445071.0</td>\n",
       "      <td>5705.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.051548</td>\n",
       "      <td>0.051986</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161.0</td>\n",
       "      <td>5645.0</td>\n",
       "      <td>592.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.016050</td>\n",
       "      <td>0.013969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3   AA4  AA6       AA7    AA14   AA15     DG1  DG3  DG3A  DG4  ...   \\\n",
       "0  3.0  32.0  6.0  323011.0  3854.0  481.0  1975.0  3.0   4.0  5.0  ...    \n",
       "1  2.0  26.0  8.0  268131.0  2441.0  344.0  1981.0  8.0   4.0  5.0  ...    \n",
       "2  1.0  16.0  7.0  167581.0   754.0  143.0  1995.0  3.0   2.0  2.0  ...    \n",
       "3  4.0  44.0  6.0  445071.0  5705.0  604.0  1980.0  3.0   4.0  5.0  ...    \n",
       "4  4.0  43.0  6.0  436161.0  5645.0  592.0  1958.0  3.0   4.0  6.0  ...    \n",
       "\n",
       "   LN2_2  LN2_3  LN2_4  LN2_RIndLngBEOth  LN2_WIndLngBEOth   GN1   GN2   GN3  \\\n",
       "0    1.0    1.0    1.0          0.670556          0.673295  99.0  99.0  99.0   \n",
       "1    1.0    3.0    4.0          0.048809          0.059326   1.0   1.0   2.0   \n",
       "2    1.0    2.0    2.0          0.670556          0.673295   1.0   2.0   2.0   \n",
       "3    1.0    4.0    5.0          0.051548          0.051986   1.0   2.0   2.0   \n",
       "4    4.0    4.0    4.0          0.016050          0.013969   1.0   1.0   1.0   \n",
       "\n",
       "    GN4   GN5  \n",
       "0  99.0  99.0  \n",
       "1   2.0   2.0  \n",
       "2   2.0   2.0  \n",
       "3  99.0  99.0  \n",
       "4   1.0   1.0  \n",
       "\n",
       "[5 rows x 360 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data predictors\n",
    "xTrain = cTrain.loc[:, ~cTrain.columns.isin([\"is_female\"])]\n",
    "xTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: is_female, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data response\n",
    "yTrain = train[\"is_female\"]\n",
    "yTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune RF Parameters\n",
    "\n",
    "Since random forests are biased towards bigger classes, let's balance class_weight. Also, let's set the minimum number of samples in leaf nodes (min_samples_leaf) to be atleast 3. By default, it is 1 which makes the model prone to detecting noise. This parameter also helps determine the maximum depth of the tree (max_depth) because the tree grows until all labels in the leaf nodes are the same (leaf purity). \n",
    "\n",
    "Let's investigate the number of trees to use in the forest (n_estimators) and whether or not out-of-bag samples should be used to estimate the generalization error (oob_score). GridSearchCV() fits a random forest model with every combination of the parameter values listed in param_grid below and prints the best parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridRF = GridSearchCV(RandomForestClassifier(class_weight=\"balanced\", \n",
    "#                                              min_samples_leaf=3, \n",
    "#                                              n_jobs=-1), \n",
    "#                       cv=5, \n",
    "#                       param_grid={\n",
    "#                           \"n_estimators\": [100, 300, 500, 700, 900],\n",
    "#                           \"oob_score\": [True, False]})\n",
    "# gridRF.fit(xTrain, yTrain)\n",
    "# gridRF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataset with 50% split\n",
    "xTrainVal, xTestVal, yTrainVal, yTestVal = train_test_split(xTrain, yTrain, test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=3,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=700, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train on validation train data\n",
    "rf =  RandomForestClassifier(n_estimators=700, \n",
    "                             class_weight=\"balanced\", \n",
    "                             min_samples_leaf=3, \n",
    "                             n_jobs=-1)\n",
    "rf.fit(X=xTrainVal, y=yTrainVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation test data\n",
    "yPredVal = rf.predict_proba(xTestVal)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95289092721796043"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Area under ROC curve\n",
    "roc_auc_score(yTestVal, yPredVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1342, 'DL0'),\n",
       " (0.0926, 'DG6'),\n",
       " (0.075, 'DL1'),\n",
       " (0.0668, 'MT1A'),\n",
       " (0.0318, 'FL4'),\n",
       " (0.0265, 'GN5'),\n",
       " (0.0263, 'DG3'),\n",
       " (0.0242, 'GN3'),\n",
       " (0.0235, 'GN4'),\n",
       " (0.0169, 'MT2'),\n",
       " (0.0165, 'DG1'),\n",
       " (0.0163, 'MT10'),\n",
       " (0.0143, 'GN2'),\n",
       " (0.013, 'DG4'),\n",
       " (0.0106, 'DG8a'),\n",
       " (0.0105, 'DL5'),\n",
       " (0.0104, 'AA14'),\n",
       " (0.0103, 'AA7'),\n",
       " (0.01, 'AA15'),\n",
       " (0.0089, 'GN1')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance\n",
    "featImp = sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), xTrain.columns), \n",
    "                 reverse=True)\n",
    "featImp[:20]  # Top 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset train and test data with feature importance score > 0.01\n",
    "topXTrain = cTrain.loc[:, [tup[1] for tup in featImp if tup[0] > 0.01]]\n",
    "topXTest = cTest.loc[:, [tup[1] for tup in featImp if tup[0] > 0.01]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-fit with important features only\n",
    "topXTrainVal, topXTestVal, yTrainVal, yTestVal = train_test_split(topXTrain, yTrain, test_size=.5)\n",
    "rf.fit(X=topXTrainVal, y=yTrainVal)\n",
    "yPredVal = rf.predict_proba(topXTestVal)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96031411737740746"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(yTestVal, yPredVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predict with RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "yTest = rf.predict_proba(topXTest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write predictions to CSV file\n",
    "submissionRF = pd.DataFrame({\"test_id\": range(0, len(yTest)), \"is_female\": yTest})\n",
    "submissionRF = submissionRF[[\"test_id\", \"is_female\"]]  # change column order\n",
    "submissionRF.to_csv(\"../submission/submissionRF.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
